# Forge_AI Docker Compose Configuration
#
# Usage:
#   docker-compose up              # Start all services
#   docker-compose up forge-api    # API server only
#   docker-compose up forge-train  # Training server only
#   docker-compose --profile dev up # Include dev tools
#
# Scale:
#   docker-compose up --scale forge-api=3  # Multiple API instances

version: '3.8'

services:
  # ===========================================
  # Main API Server (GPU)
  # ===========================================
  forge-api:
    build:
      context: .
      dockerfile: Dockerfile
      target: final
    image: forge-ai:latest
    container_name: forge-api
    restart: unless-stopped
    ports:
      - "8000:8000"
    volumes:
      - ./models:/app/models
      - ./data:/app/data
      - ./outputs:/app/outputs
      - ./logs:/app/logs
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - FORGE_LOG_LEVEL=INFO
      - FORGE_MAX_BATCH_SIZE=32
      - FORGE_MAX_TOKENS=4096
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - forge-network

  # ===========================================
  # CPU-Only API Server (for testing/low-resource)
  # ===========================================
  forge-api-cpu:
    build:
      context: .
      dockerfile: Dockerfile
      target: cpu-only
    image: forge-ai:cpu
    container_name: forge-api-cpu
    restart: unless-stopped
    profiles:
      - cpu
    ports:
      - "8001:8000"
    volumes:
      - ./models:/app/models
      - ./data:/app/data
      - ./outputs:/app/outputs
      - ./logs:/app/logs
    environment:
      - CUDA_VISIBLE_DEVICES=""
      - FORGE_LOG_LEVEL=INFO
    networks:
      - forge-network

  # ===========================================
  # Training Server (GPU)
  # ===========================================
  forge-train:
    build:
      context: .
      dockerfile: Dockerfile
      target: final
    image: forge-ai:latest
    container_name: forge-train
    profiles:
      - train
    volumes:
      - ./models:/app/models
      - ./data:/app/data
      - ./outputs:/app/outputs
      - ./logs:/app/logs
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - FORGE_LOG_LEVEL=DEBUG
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    command: ["python", "run.py", "--train"]
    networks:
      - forge-network

  # ===========================================
  # Vector Database (for RAG)
  # ===========================================
  qdrant:
    image: qdrant/qdrant:latest
    container_name: forge-qdrant
    restart: unless-stopped
    profiles:
      - rag
      - full
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant-storage:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
    networks:
      - forge-network

  # ===========================================
  # Redis (for caching/rate limiting)
  # ===========================================
  redis:
    image: redis:7-alpine
    container_name: forge-redis
    restart: unless-stopped
    profiles:
      - cache
      - full
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes
    networks:
      - forge-network

  # ===========================================
  # Prometheus (metrics collection)
  # ===========================================
  prometheus:
    image: prom/prometheus:latest
    container_name: forge-prometheus
    restart: unless-stopped
    profiles:
      - monitoring
      - full
    ports:
      - "9090:9090"
    volumes:
      - ./docker/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    networks:
      - forge-network

  # ===========================================
  # Grafana (metrics visualization)
  # ===========================================
  grafana:
    image: grafana/grafana:latest
    container_name: forge-grafana
    restart: unless-stopped
    profiles:
      - monitoring
      - full
    ports:
      - "3000:3000"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./docker/grafana/provisioning:/etc/grafana/provisioning
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=forge-admin
      - GF_USERS_ALLOW_SIGN_UP=false
    depends_on:
      - prometheus
    networks:
      - forge-network

  # ===========================================
  # Nginx Load Balancer (for multiple API instances)
  # ===========================================
  nginx:
    image: nginx:alpine
    container_name: forge-nginx
    restart: unless-stopped
    profiles:
      - production
      - full
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./docker/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./docker/ssl:/etc/nginx/ssl:ro
    depends_on:
      - forge-api
    networks:
      - forge-network

# ===========================================
# Networks
# ===========================================
networks:
  forge-network:
    driver: bridge

# ===========================================
# Volumes
# ===========================================
volumes:
  qdrant-storage:
  redis-data:
  prometheus-data:
  grafana-data:
