ENIGMA AI - QUICK HELP
=======================

GETTING STARTED
---------------
1. Run: python run.py --gui
2. The AI runs in system tray when you close the window
3. Use voice or keyboard to talk to it anytime

KEYBOARD SHORTCUTS
------------------
Alt+F4              Close the window
Ctrl+Shift+F4       Emergency quit (force close)

VOICE COMMANDS
--------------
Say "Hey ForgeAI" then speak your command:
- "Take a screenshot"
- "Generate an image of a sunset"
- "What's on my screen?"
- "Start recording"
- "Open the interface"

SIDEBAR TABS
------------
MAIN:
  Chat      - Talk to AI
  Train     - Teach your AI
  History   - Past conversations
  Scale     - Choose model size
  Modules   - Enable/disable features
  Router    - Assign AI models to tools

GENERATE:
  Image     - Generate images
  Code      - Generate code
  Video     - Generate videos
  Audio     - Text-to-speech
  3D        - Generate 3D models
  GIF       - Create animations

CONNECT:
  Search    - Semantic search
  Avatar    - Visual AI rep (desktop overlay)
  Game      - Game connections
  Robot     - Robot control
  Vision    - Screen capture
  Camera    - Live camera feed

AVATAR (Desktop Overlay)
------------------------
The avatar is a draggable desktop companion:

Controls:
  - Drag to move around screen
  - Scroll wheel to resize (100-500px)
  - Double-click to reset size
  - Right-click for options menu
  - ESC to hide

Right-Click Menu:
  - Style: Switch between Blob and Anime Girl
  - Expression: Change facial expression
  - Size: Set specific size (150-500px)
  - Reset Position: Move to top-left
  - Change Avatar: Load custom image/model
  - Close Avatar: Hide from desktop

Supported Avatar Files:
  - Images: PNG, JPG, GIF, BMP, WEBP
  - 3D Models: GLB, GLTF, OBJ, FBX, DAE

Add custom avatars to: data/avatar/models/
The avatar closes automatically when you exit the GUI.

TOOLS:
  Terminal  - Command line
  Files     - Training data
  Examples  - Usage examples
  Settings  - Configuration

AVAILABLE AI TOOLS (26 Total)
-----------------------------
The AI can use these tools during conversation:

FILE TOOLS:
  read_file       - Read file contents
  write_file      - Create/modify files
  list_directory  - Browse folders
  move_file       - Move/rename files
  delete_file     - Remove files
  read_document   - Parse PDFs, docs
  extract_text    - Get text from files

WEB TOOLS:
  web_search      - Search the internet
  fetch_webpage   - Get web page content

SYSTEM TOOLS:
  run_command     - Execute terminal commands
  screenshot      - Capture screen
  get_system_info - System resources

VISION TOOLS:
  see_screen      - Describe what's on screen
  find_on_screen  - Locate text/elements

ROBOT TOOLS:
  robot_move      - Move robot joints
  robot_gripper   - Control gripper
  robot_status    - Get robot state
  robot_home      - Return to home position

INTERACTIVE TOOLS (Personal Assistant):
  create_checklist - Create a new checklist
  list_checklists  - View all checklists
  add_task         - Add tasks to checklist
  list_tasks       - View tasks
  complete_task    - Mark task done
  set_reminder     - Set a reminder
  list_reminders   - View reminders
  check_reminders  - Check due reminders

MODEL ROUTER (NEW!)
-------------------
Go to Router tab to:
- See all available tools (chat, image, code, etc.)
- Assign any model to any tool
- Click "Apply to ALL Tools" to use one model everywhere
- Supports Enigma, HuggingFace, and API models

Recommended for Raspberry Pi:
- Qwen/Qwen2-0.5B-Instruct (503M params)
- TinyLlama/TinyLlama-1.1B-Chat-v1.0 (1.1B params)

CAMERA TAB (NEW!)
-----------------
- Live preview from webcam/camera
- Capture photos to information/images/
- Record video (AVI format)
- AI can analyze what camera sees
- Requires: pip install opencv-python

CHAT NAMES (NEW!)
-----------------
- Go to Settings -> Chat Names
- Set your display name (instead of "You")
- AI displays its actual model name (e.g., "mistralai_mistral_7b")
- Names are saved and remembered across sessions

IMAGE GENERATION
----------------
Generating images requires one of these providers:

1. LOCAL (Stable Diffusion) - Best quality, runs on your GPU
   - Requires: GPU with 8GB+ VRAM
   - Requires: pip install diffusers transformers accelerate torch
   - Select "Local (Stable Diffusion)" in Image tab
   - Click "Load Model" (downloads ~4GB first time)

2. OPENAI (DALL-E 3) - Cloud service
   - Requires: OpenAI API key in Settings -> API Keys
   - Costs money per image

3. REPLICATE (SDXL/Flux) - Cloud service
   - Requires: Replicate API key in Settings -> API Keys
   - Costs money per image

4. PLACEHOLDER - For testing (no real AI)
   - Creates blue image with your prompt text
   - No requirements, works immediately

FILES AND FOLDERS
-----------------
outputs/images/     Generated images
outputs/videos/     Recordings and videos
outputs/audio/      Generated audio
outputs/code/       Generated code
data/               Training data
models/             AI models
information/images/ Camera captures

NEED MORE HELP?
---------------
- Full docs: docs/ folder
- Instructions: information/instructions.txt
- GUI Guide: docs/GUI_GUIDE.md
- Training: docs/HOW_TO_TRAIN.md

TIP: Use the Router tab's "Apply to ALL" button
to quickly set your preferred AI model everywhere!
